## Классификация текстов по признаку токсичности

Интернет-магазином «Викишоп» поставлена задача: обучить модель классифицировать комментарии как позитивные и негативные. Важно построить модель со значением метрики качества F1 не меньше 0.75.

Для решения задачи проделаны следующие шаги:

Подготовка данных

На данном этапе:

Удалён столбец Unnamed: 0.
Проведена процедура андерсэмплинга. Количество значений мажорного класса (нетоксичные комментарии) приравнено к количеству данных минорного (токсичные комментарии).
Предобученный BERT использован для получения эмбеддингов.
Обучение моделей

Были обучены следующие модели:

LogisticRegression

f1 на кросс-валидации: 0.889274338274037
Среднее время обучения модели: 9.495832840601603 cекунд
RandomForest

Гиперпараметры лучшей модели:

class_weight='balanced'

max_depth=17

min_samples_leaf=4

min_samples_split=5

n_estimators=28

random_state=42

f1 на кросс-валидации: 0.9138714476104024

Среднее время обучения модели: 9.164213705062867 cекунд

CatBoost

f1 на кросс-валидации: 0.9187129290314258
Среднее время обучения модели: 123.75585714975993 cекунд
Все модели преодолели порог качества на кросс-валидации.

Модель градиентного бустинга незначительно лучше модели случайного леса, но вторая заметно быстрее. Для тестирования выберем случайный лес.

F1 лучшей модели на тестовой выборке: 0.9193548387096774
